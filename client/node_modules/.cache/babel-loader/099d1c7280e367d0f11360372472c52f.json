{"ast":null,"code":"'use strict'; // this[BUFFER] is the remainder of a chunk if we're waiting for\n// the full 512 bytes of a header to come in.  We will Buffer.concat()\n// it to the next write(), which is a mem copy, but a small one.\n//\n// this[QUEUE] is a Yallist of entries that haven't been emitted\n// yet this can only get filled up if the user keeps write()ing after\n// a write() returns false, or does a write() with more than one entry\n//\n// We don't buffer chunks, we always parse them and either create an\n// entry, or push it into the active entry.  The ReadEntry class knows\n// to throw data away if .ignore=true\n//\n// Shift entry off the buffer when it emits 'end', and emit 'entry' for\n// the next one in the list.\n//\n// At any time, we're pushing body chunks into the entry at WRITEENTRY,\n// and waiting for 'end' on the entry at READENTRY\n//\n// ignored entries get .resume() called on them straight away\n\nconst warner = require('./warn-mixin.js');\n\nconst Header = require('./header.js');\n\nconst EE = require('events');\n\nconst Yallist = require('yallist');\n\nconst maxMetaEntrySize = 1024 * 1024;\n\nconst Entry = require('./read-entry.js');\n\nconst Pax = require('./pax.js');\n\nconst zlib = require('minizlib');\n\nconst gzipHeader = Buffer.from([0x1f, 0x8b]);\nconst STATE = Symbol('state');\nconst WRITEENTRY = Symbol('writeEntry');\nconst READENTRY = Symbol('readEntry');\nconst NEXTENTRY = Symbol('nextEntry');\nconst PROCESSENTRY = Symbol('processEntry');\nconst EX = Symbol('extendedHeader');\nconst GEX = Symbol('globalExtendedHeader');\nconst META = Symbol('meta');\nconst EMITMETA = Symbol('emitMeta');\nconst BUFFER = Symbol('buffer');\nconst QUEUE = Symbol('queue');\nconst ENDED = Symbol('ended');\nconst EMITTEDEND = Symbol('emittedEnd');\nconst EMIT = Symbol('emit');\nconst UNZIP = Symbol('unzip');\nconst CONSUMECHUNK = Symbol('consumeChunk');\nconst CONSUMECHUNKSUB = Symbol('consumeChunkSub');\nconst CONSUMEBODY = Symbol('consumeBody');\nconst CONSUMEMETA = Symbol('consumeMeta');\nconst CONSUMEHEADER = Symbol('consumeHeader');\nconst CONSUMING = Symbol('consuming');\nconst BUFFERCONCAT = Symbol('bufferConcat');\nconst MAYBEEND = Symbol('maybeEnd');\nconst WRITING = Symbol('writing');\nconst ABORTED = Symbol('aborted');\nconst DONE = Symbol('onDone');\nconst SAW_VALID_ENTRY = Symbol('sawValidEntry');\nconst SAW_NULL_BLOCK = Symbol('sawNullBlock');\nconst SAW_EOF = Symbol('sawEOF');\n\nconst noop = _ => true;\n\nmodule.exports = warner(class Parser extends EE {\n  constructor(opt) {\n    opt = opt || {};\n    super(opt);\n    this.file = opt.file || ''; // set to boolean false when an entry starts.  1024 bytes of \\0\n    // is technically a valid tarball, albeit a boring one.\n\n    this[SAW_VALID_ENTRY] = null; // these BADARCHIVE errors can't be detected early. listen on DONE.\n\n    this.on(DONE, _ => {\n      if (this[STATE] === 'begin' || this[SAW_VALID_ENTRY] === false) {\n        // either less than 1 block of data, or all entries were invalid.\n        // Either way, probably not even a tarball.\n        this.warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format');\n      }\n    });\n    if (opt.ondone) this.on(DONE, opt.ondone);else {\n      this.on(DONE, _ => {\n        this.emit('prefinish');\n        this.emit('finish');\n        this.emit('end');\n        this.emit('close');\n      });\n    }\n    this.strict = !!opt.strict;\n    this.maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize;\n    this.filter = typeof opt.filter === 'function' ? opt.filter : noop; // have to set this so that streams are ok piping into it\n\n    this.writable = true;\n    this.readable = false;\n    this[QUEUE] = new Yallist();\n    this[BUFFER] = null;\n    this[READENTRY] = null;\n    this[WRITEENTRY] = null;\n    this[STATE] = 'begin';\n    this[META] = '';\n    this[EX] = null;\n    this[GEX] = null;\n    this[ENDED] = false;\n    this[UNZIP] = null;\n    this[ABORTED] = false;\n    this[SAW_NULL_BLOCK] = false;\n    this[SAW_EOF] = false;\n    if (typeof opt.onwarn === 'function') this.on('warn', opt.onwarn);\n    if (typeof opt.onentry === 'function') this.on('entry', opt.onentry);\n  }\n\n  [CONSUMEHEADER](chunk, position) {\n    if (this[SAW_VALID_ENTRY] === null) this[SAW_VALID_ENTRY] = false;\n    let header;\n\n    try {\n      header = new Header(chunk, position, this[EX], this[GEX]);\n    } catch (er) {\n      return this.warn('TAR_ENTRY_INVALID', er);\n    }\n\n    if (header.nullBlock) {\n      if (this[SAW_NULL_BLOCK]) {\n        this[SAW_EOF] = true; // ending an archive with no entries.  pointless, but legal.\n\n        if (this[STATE] === 'begin') this[STATE] = 'header';\n        this[EMIT]('eof');\n      } else {\n        this[SAW_NULL_BLOCK] = true;\n        this[EMIT]('nullBlock');\n      }\n    } else {\n      this[SAW_NULL_BLOCK] = false;\n      if (!header.cksumValid) this.warn('TAR_ENTRY_INVALID', 'checksum failure', {\n        header\n      });else if (!header.path) this.warn('TAR_ENTRY_INVALID', 'path is required', {\n        header\n      });else {\n        const type = header.type;\n        if (/^(Symbolic)?Link$/.test(type) && !header.linkpath) this.warn('TAR_ENTRY_INVALID', 'linkpath required', {\n          header\n        });else if (!/^(Symbolic)?Link$/.test(type) && header.linkpath) this.warn('TAR_ENTRY_INVALID', 'linkpath forbidden', {\n          header\n        });else {\n          const entry = this[WRITEENTRY] = new Entry(header, this[EX], this[GEX]); // we do this for meta & ignored entries as well, because they\n          // are still valid tar, or else we wouldn't know to ignore them\n\n          if (!this[SAW_VALID_ENTRY]) {\n            if (entry.remain) {\n              // this might be the one!\n              const onend = () => {\n                if (!entry.invalid) this[SAW_VALID_ENTRY] = true;\n              };\n\n              entry.on('end', onend);\n            } else this[SAW_VALID_ENTRY] = true;\n          }\n\n          if (entry.meta) {\n            if (entry.size > this.maxMetaEntrySize) {\n              entry.ignore = true;\n              this[EMIT]('ignoredEntry', entry);\n              this[STATE] = 'ignore';\n              entry.resume();\n            } else if (entry.size > 0) {\n              this[META] = '';\n              entry.on('data', c => this[META] += c);\n              this[STATE] = 'meta';\n            }\n          } else {\n            this[EX] = null;\n            entry.ignore = entry.ignore || !this.filter(entry.path, entry);\n\n            if (entry.ignore) {\n              // probably valid, just not something we care about\n              this[EMIT]('ignoredEntry', entry);\n              this[STATE] = entry.remain ? 'ignore' : 'header';\n              entry.resume();\n            } else {\n              if (entry.remain) this[STATE] = 'body';else {\n                this[STATE] = 'header';\n                entry.end();\n              }\n\n              if (!this[READENTRY]) {\n                this[QUEUE].push(entry);\n                this[NEXTENTRY]();\n              } else this[QUEUE].push(entry);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  [PROCESSENTRY](entry) {\n    let go = true;\n\n    if (!entry) {\n      this[READENTRY] = null;\n      go = false;\n    } else if (Array.isArray(entry)) this.emit.apply(this, entry);else {\n      this[READENTRY] = entry;\n      this.emit('entry', entry);\n\n      if (!entry.emittedEnd) {\n        entry.on('end', _ => this[NEXTENTRY]());\n        go = false;\n      }\n    }\n\n    return go;\n  }\n\n  [NEXTENTRY]() {\n    do {} while (this[PROCESSENTRY](this[QUEUE].shift()));\n\n    if (!this[QUEUE].length) {\n      // At this point, there's nothing in the queue, but we may have an\n      // entry which is being consumed (readEntry).\n      // If we don't, then we definitely can handle more data.\n      // If we do, and either it's flowing, or it has never had any data\n      // written to it, then it needs more.\n      // The only other possibility is that it has returned false from a\n      // write() call, so we wait for the next drain to continue.\n      const re = this[READENTRY];\n      const drainNow = !re || re.flowing || re.size === re.remain;\n\n      if (drainNow) {\n        if (!this[WRITING]) this.emit('drain');\n      } else re.once('drain', _ => this.emit('drain'));\n    }\n  }\n\n  [CONSUMEBODY](chunk, position) {\n    // write up to but no  more than writeEntry.blockRemain\n    const entry = this[WRITEENTRY];\n    const br = entry.blockRemain;\n    const c = br >= chunk.length && position === 0 ? chunk : chunk.slice(position, position + br);\n    entry.write(c);\n\n    if (!entry.blockRemain) {\n      this[STATE] = 'header';\n      this[WRITEENTRY] = null;\n      entry.end();\n    }\n\n    return c.length;\n  }\n\n  [CONSUMEMETA](chunk, position) {\n    const entry = this[WRITEENTRY];\n    const ret = this[CONSUMEBODY](chunk, position); // if we finished, then the entry is reset\n\n    if (!this[WRITEENTRY]) this[EMITMETA](entry);\n    return ret;\n  }\n\n  [EMIT](ev, data, extra) {\n    if (!this[QUEUE].length && !this[READENTRY]) this.emit(ev, data, extra);else this[QUEUE].push([ev, data, extra]);\n  }\n\n  [EMITMETA](entry) {\n    this[EMIT]('meta', this[META]);\n\n    switch (entry.type) {\n      case 'ExtendedHeader':\n      case 'OldExtendedHeader':\n        this[EX] = Pax.parse(this[META], this[EX], false);\n        break;\n\n      case 'GlobalExtendedHeader':\n        this[GEX] = Pax.parse(this[META], this[GEX], true);\n        break;\n\n      case 'NextFileHasLongPath':\n      case 'OldGnuLongPath':\n        this[EX] = this[EX] || Object.create(null);\n        this[EX].path = this[META].replace(/\\0.*/, '');\n        break;\n\n      case 'NextFileHasLongLinkpath':\n        this[EX] = this[EX] || Object.create(null);\n        this[EX].linkpath = this[META].replace(/\\0.*/, '');\n        break;\n\n      /* istanbul ignore next */\n\n      default:\n        throw new Error('unknown meta: ' + entry.type);\n    }\n  }\n\n  abort(error) {\n    this[ABORTED] = true;\n    this.emit('abort', error); // always throws, even in non-strict mode\n\n    this.warn('TAR_ABORT', error, {\n      recoverable: false\n    });\n  }\n\n  write(chunk) {\n    if (this[ABORTED]) return; // first write, might be gzipped\n\n    if (this[UNZIP] === null && chunk) {\n      if (this[BUFFER]) {\n        chunk = Buffer.concat([this[BUFFER], chunk]);\n        this[BUFFER] = null;\n      }\n\n      if (chunk.length < gzipHeader.length) {\n        this[BUFFER] = chunk;\n        return true;\n      }\n\n      for (let i = 0; this[UNZIP] === null && i < gzipHeader.length; i++) {\n        if (chunk[i] !== gzipHeader[i]) this[UNZIP] = false;\n      }\n\n      if (this[UNZIP] === null) {\n        const ended = this[ENDED];\n        this[ENDED] = false;\n        this[UNZIP] = new zlib.Unzip();\n        this[UNZIP].on('data', chunk => this[CONSUMECHUNK](chunk));\n        this[UNZIP].on('error', er => this.abort(er));\n        this[UNZIP].on('end', _ => {\n          this[ENDED] = true;\n          this[CONSUMECHUNK]();\n        });\n        this[WRITING] = true;\n        const ret = this[UNZIP][ended ? 'end' : 'write'](chunk);\n        this[WRITING] = false;\n        return ret;\n      }\n    }\n\n    this[WRITING] = true;\n    if (this[UNZIP]) this[UNZIP].write(chunk);else this[CONSUMECHUNK](chunk);\n    this[WRITING] = false; // return false if there's a queue, or if the current entry isn't flowing\n\n    const ret = this[QUEUE].length ? false : this[READENTRY] ? this[READENTRY].flowing : true; // if we have no queue, then that means a clogged READENTRY\n\n    if (!ret && !this[QUEUE].length) this[READENTRY].once('drain', _ => this.emit('drain'));\n    return ret;\n  }\n\n  [BUFFERCONCAT](c) {\n    if (c && !this[ABORTED]) this[BUFFER] = this[BUFFER] ? Buffer.concat([this[BUFFER], c]) : c;\n  }\n\n  [MAYBEEND]() {\n    if (this[ENDED] && !this[EMITTEDEND] && !this[ABORTED] && !this[CONSUMING]) {\n      this[EMITTEDEND] = true;\n      const entry = this[WRITEENTRY];\n\n      if (entry && entry.blockRemain) {\n        // truncated, likely a damaged file\n        const have = this[BUFFER] ? this[BUFFER].length : 0;\n        this.warn('TAR_BAD_ARCHIVE', `Truncated input (needed ${entry.blockRemain} more bytes, only ${have} available)`, {\n          entry\n        });\n        if (this[BUFFER]) entry.write(this[BUFFER]);\n        entry.end();\n      }\n\n      this[EMIT](DONE);\n    }\n  }\n\n  [CONSUMECHUNK](chunk) {\n    if (this[CONSUMING]) this[BUFFERCONCAT](chunk);else if (!chunk && !this[BUFFER]) this[MAYBEEND]();else {\n      this[CONSUMING] = true;\n\n      if (this[BUFFER]) {\n        this[BUFFERCONCAT](chunk);\n        const c = this[BUFFER];\n        this[BUFFER] = null;\n        this[CONSUMECHUNKSUB](c);\n      } else this[CONSUMECHUNKSUB](chunk);\n\n      while (this[BUFFER] && this[BUFFER].length >= 512 && !this[ABORTED] && !this[SAW_EOF]) {\n        const c = this[BUFFER];\n        this[BUFFER] = null;\n        this[CONSUMECHUNKSUB](c);\n      }\n\n      this[CONSUMING] = false;\n    }\n    if (!this[BUFFER] || this[ENDED]) this[MAYBEEND]();\n  }\n\n  [CONSUMECHUNKSUB](chunk) {\n    // we know that we are in CONSUMING mode, so anything written goes into\n    // the buffer.  Advance the position and put any remainder in the buffer.\n    let position = 0;\n    const length = chunk.length;\n\n    while (position + 512 <= length && !this[ABORTED] && !this[SAW_EOF]) {\n      switch (this[STATE]) {\n        case 'begin':\n        case 'header':\n          this[CONSUMEHEADER](chunk, position);\n          position += 512;\n          break;\n\n        case 'ignore':\n        case 'body':\n          position += this[CONSUMEBODY](chunk, position);\n          break;\n\n        case 'meta':\n          position += this[CONSUMEMETA](chunk, position);\n          break;\n\n        /* istanbul ignore next */\n\n        default:\n          throw new Error('invalid state: ' + this[STATE]);\n      }\n    }\n\n    if (position < length) {\n      if (this[BUFFER]) this[BUFFER] = Buffer.concat([chunk.slice(position), this[BUFFER]]);else this[BUFFER] = chunk.slice(position);\n    }\n  }\n\n  end(chunk) {\n    if (!this[ABORTED]) {\n      if (this[UNZIP]) this[UNZIP].end(chunk);else {\n        this[ENDED] = true;\n        this.write(chunk);\n      }\n    }\n  }\n\n});","map":null,"metadata":{},"sourceType":"script"}